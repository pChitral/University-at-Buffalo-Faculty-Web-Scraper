{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import re\n",
    "import logging\n",
    "\n",
    "\n",
    "class FacultyScraper:\n",
    "    \"\"\"\n",
    "    A web scraping tool to extract data from a faculty directory website.\n",
    "\n",
    "    Attributes:\n",
    "        url (str): The URL of the faculty directory website.\n",
    "        session (requests.Session): A session object to handle HTTP requests.\n",
    "        soup (BeautifulSoup): A BeautifulSoup object to parse HTML content.\n",
    "        list_of_dicts (list): A list of dictionaries containing faculty information.\n",
    "\n",
    "    Methods:\n",
    "        scrape_data(): Scrapes the data from the faculty directory website.\n",
    "        make_request(): Sends an HTTP request to the specified URL.\n",
    "        parse_html(): Parses the HTML content of the response.\n",
    "        find_email_addresses(): Finds and stores the email addresses of faculty members.\n",
    "        find_professors(): Finds and stores the names and colleges of faculty members.\n",
    "        check_length(): Checks if the number of unique emails matches the number of faculty names.\n",
    "        find_links(): Finds and stores the profile links of faculty members.\n",
    "        create_faculty_dicts(): Creates faculty dictionaries with basic information.\n",
    "        extract_subjects(): Extracts and stores the subjects taught by each faculty member.\n",
    "        extract_research_topics(): Extracts and stores the research topics of each faculty member.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Initializes a FacultyScraper object.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the faculty directory website.\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.session = requests.Session()\n",
    "        self.soup = None\n",
    "        self.list_of_dicts = []\n",
    "        self.logger = self._setup_logger()\n",
    "\n",
    "    def _setup_logger(self):\n",
    "        \"\"\"\n",
    "        Sets up a logger for error handling and logging.\n",
    "\n",
    "        Returns:\n",
    "            logging.Logger: The configured logger object.\n",
    "        \"\"\"\n",
    "        logger = logging.getLogger(\"FacultyScraper\")\n",
    "        logger.setLevel(logging.ERROR)\n",
    "\n",
    "        # Define log file handler\n",
    "        file_handler = logging.FileHandler(\"scraper.log\")\n",
    "        file_handler.setLevel(logging.ERROR)\n",
    "\n",
    "        # Define log message format\n",
    "        formatter = logging.Formatter(\n",
    "            \"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "        file_handler.setFormatter(formatter)\n",
    "\n",
    "        # Add file handler to logger\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "        return logger\n",
    "\n",
    "    def scrape_data(self):\n",
    "        \"\"\"\n",
    "        Scrapes the data from the faculty directory website.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of dictionaries containing faculty information.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.make_request()\n",
    "            self.parse_html()\n",
    "            self.find_email_addresses()\n",
    "            self.find_professors()\n",
    "            self.check_length()\n",
    "            self.find_links()\n",
    "            self.create_faculty_dicts()\n",
    "\n",
    "            # Create a ThreadPoolExecutor with maximum threads\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "                # Execute extract_subjects and extract_research_topics concurrently\n",
    "                subject_futures = [executor.submit(\n",
    "                    self.extract_subjects, url) for url in self.links]\n",
    "                research_futures = [executor.submit(\n",
    "                    self.extract_research_topics, url) for url in self.links]\n",
    "\n",
    "                # Retrieve the results from the futures\n",
    "                subjects_list = [\n",
    "                    future.result() for future in concurrent.futures.as_completed(subject_futures)]\n",
    "                research_list = [\n",
    "                    future.result() for future in concurrent.futures.as_completed(research_futures)]\n",
    "\n",
    "            # Update the subjects and research topics in the faculty dictionaries\n",
    "            for i in range(len(self.list_of_dicts)):\n",
    "                self.list_of_dicts[i][\"Subjects\"] = subjects_list[i]\n",
    "                self.list_of_dicts[i][\"Research\"] = research_list[i]\n",
    "\n",
    "            return self.list_of_dicts\n",
    "        except Exception as e:\n",
    "            self.logger.error(\"An error occurred during scraping: %s\", str(e))\n",
    "\n",
    "    def make_request(self):\n",
    "        \"\"\"\n",
    "        Sends an HTTP request to the specified URL.\n",
    "        \"\"\"\n",
    "        self.response = self.session.get(self.url)\n",
    "\n",
    "    def parse_html(self):\n",
    "        \"\"\"\n",
    "        Parses the HTML content of the response.\n",
    "        \"\"\"\n",
    "        self.soup = BeautifulSoup(self.response.content, \"html.parser\")\n",
    "\n",
    "    def find_email_addresses(self):\n",
    "        \"\"\"\n",
    "        Finds and stores the email addresses of faculty members.\n",
    "        \"\"\"\n",
    "        email_addresses = [\n",
    "            link.get(\"href\").replace(\"mailto:\", \"\")\n",
    "            for link in self.soup.find_all(\"a\", href=lambda href: href and href.startswith(\"mailto:\"))\n",
    "        ]\n",
    "        self.unique_emails = []\n",
    "        for mail in email_addresses:\n",
    "            if mail not in self.unique_emails:\n",
    "                self.unique_emails.append(mail)\n",
    "\n",
    "    def validate_email_format(self, email):\n",
    "        \"\"\"\n",
    "        Validates if an email address is in the correct format.\n",
    "\n",
    "        Args:\n",
    "            email (str): Email address to validate.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the email is valid, False otherwise.\n",
    "        \"\"\"\n",
    "        pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "        return re.match(pattern, email) is not None\n",
    "\n",
    "    def clean_data(self):\n",
    "        \"\"\"\n",
    "        Cleans the scraped data by removing duplicates and handling missing values.\n",
    "        \"\"\"\n",
    "        unique_emails = []\n",
    "        cleaned_data = []\n",
    "\n",
    "        for faculty in self.list_of_dicts:\n",
    "            email = faculty[\"Email\"]\n",
    "            if email and email not in unique_emails:\n",
    "                unique_emails.append(email)\n",
    "                cleaned_data.append(faculty)\n",
    "\n",
    "        self.list_of_dicts = cleaned_data\n",
    "\n",
    "        # Validate and clean email addresses\n",
    "        for faculty in self.list_of_dicts:\n",
    "            email = faculty[\"Email\"]\n",
    "            if email and not self.validate_email_format(email):\n",
    "                faculty[\"Email\"] = \"\"\n",
    "\n",
    "        # Handle missing values\n",
    "        for faculty in self.list_of_dicts:\n",
    "            for key, value in faculty.items():\n",
    "                if value is None:\n",
    "                    faculty[key] = \"\"\n",
    "\n",
    "    def find_professors(self):\n",
    "        \"\"\"\n",
    "        Finds and stores the names and colleges of faculty members.\n",
    "        \"\"\"\n",
    "        professors = self.soup.find_all(\n",
    "            \"div\", class_=\"profileinfo-teaser-name\")\n",
    "        self.names = []\n",
    "        self.prof_college = []\n",
    "        for div in professors:\n",
    "            name_parts = div.text.split(',')\n",
    "            name = name_parts[0].strip()\n",
    "            self.prof_college.append(name_parts[2].strip())\n",
    "            if \"PhD\" in name_parts[1]:\n",
    "                new_name = \"Dr. \" + name\n",
    "                self.names.append(new_name)\n",
    "            else:\n",
    "                self.names.append(name)\n",
    "\n",
    "    def check_length(self):\n",
    "        \"\"\"\n",
    "        Checks if the number of unique emails matches the number of faculty names.\n",
    "        \"\"\"\n",
    "        self.is_length_equal = len(self.unique_emails) == len(self.names)\n",
    "\n",
    "    def find_links(self):\n",
    "        \"\"\"\n",
    "        Finds and stores the profile links of faculty members.\n",
    "        \"\"\"\n",
    "        professors = self.soup.find_all(\n",
    "            \"div\", class_=\"profileinfo-teaser-name\")\n",
    "        self.links = [\n",
    "            \"https://engineering.buffalo.edu/\" +\n",
    "            div.find('a', class_='title')['href'][:-4] + \"teaching.html\"\n",
    "            for div in professors\n",
    "        ]\n",
    "\n",
    "    def create_faculty_dicts(self):\n",
    "        \"\"\"\n",
    "        Creates faculty dictionaries with basic information.\n",
    "        \"\"\"\n",
    "        for name, college, email, profile_url in zip(self.names, self.prof_college, self.unique_emails, self.links):\n",
    "            faculty_dict = {\n",
    "                \"Name\": name,\n",
    "                \"College\": college,\n",
    "                \"Email\": email,\n",
    "                \"Subjects\": [],\n",
    "                \"Research\": [],\n",
    "                \"Profile\": profile_url  # Add the 'Profile' key with the URL\n",
    "            }\n",
    "            self.list_of_dicts.append(faculty_dict)\n",
    "\n",
    "    def extract_subjects(self, url):\n",
    "        \"\"\"\n",
    "        Extracts and returns the subjects taught by a faculty member.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the faculty member's profile page.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of subjects taught by the faculty member.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.session.get(url)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            div = soup.find(\"div\", class_=\"text parbase section\")\n",
    "            ul = div.find(\"ul\")\n",
    "            subjects = []\n",
    "            try:\n",
    "                for li in ul.find_all(\"li\"):\n",
    "                    subjects.append(li.text)\n",
    "            except:\n",
    "                pass\n",
    "            return subjects\n",
    "        except Exception as e:\n",
    "            self.logger.error(\n",
    "                \"An error occurred during subject extraction: %s\", str(e))\n",
    "\n",
    "    def extract_research_topics(self, url):\n",
    "        \"\"\"\n",
    "        Extracts and returns the research topics of a faculty member.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the faculty member's profile page.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of research topics of the faculty member.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.session.get(url)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            research_topics = []\n",
    "            try:\n",
    "                for div in soup.find_all(\"div\", class_=\"profileinfo-interest title\"):\n",
    "                    raw_string = div.text[15:].strip()\n",
    "                    research_topics.extend(raw_string.strip().split(\"; \"))\n",
    "            except:\n",
    "                pass\n",
    "            return research_topics\n",
    "        except Exception as e:\n",
    "            self.logger.error(\n",
    "                \"An error occurred during research topic extraction: %s\", str(e))\n",
    "\n",
    "    def dump_to_csv(self, filename):\n",
    "        \"\"\"\n",
    "        Dumps the scraped data to a CSV file.\n",
    "\n",
    "        Args:\n",
    "            filename (str): The name of the CSV file.\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(self.list_of_dicts)\n",
    "        df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://engineering.buffalo.edu/computer-science-engineering/people/faculty-directory/full-time.html\"\n",
    "scraper = FacultyScraper(url)\n",
    "data = scraper.scrape_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.dump_to_csv('Department of Computer Science and Engineering Faculty Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
